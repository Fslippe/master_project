{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "from keras.layers import Input, Dense, Flatten, Reshape\n",
    "from sklearn.feature_extraction import image as sk_image\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import cartopy.feature as cfeature\n",
    "from keras.models import Model\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.signal import convolve2d \n",
    "from scipy import ndimage\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras    \n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from sklearn.cluster import DBSCAN\n",
    "from pyhdf.SD import SD, SDC\n",
    "import matplotlib as mpl\n",
    "#tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "from extract_training_data import *\n",
    "from sklearn.feature_extraction.image import extract_patches_2d, reconstruct_from_patches_2d\n",
    "from pyhdf.error import HDF4Error\n",
    "from functions import *\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "import joblib\n",
    "import plot_functions\n",
    "import importlib \n",
    "importlib.reload(plot_functions)\n",
    "from plot_functions import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\"  , len(logical_gpus), \"Logical GPUs\")\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "if \"nird\" in hostname:\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(8)\n",
    "    data_loc = \"/nird/projects/NS9600K/fslippe/data/\"\n",
    "    folder = \"/nird/projects/NS9600K/data/modis/cao/MOD02/2020/ /nird/projects/NS9600K/data/modis/cao/MOD02/2021/ /nird/projects/NS9600K/data/modis/cao/MOD02/2023/\"\n",
    "if \"mimi\" in hostname:\n",
    "    data_loc = \"/uio/hume/student-u37/fslippe/data/\"\n",
    "    folder = \"/scratch/fslippe/modis/MOD02/2019/ /scratch/fslippe/modis/MOD02/2020/ /scratch/fslippe/modis/MOD02/2021/ /scratch/fslippe/modis/MOD02/2022/ /scratch/fslippe/modis/MOD02/2023/ /scratch/fslippe/modis/MOD02/daytime_1km/ /scratch/fslippe/modis/MOD02/boundary_1km/ /scratch/fslippe/modis/MOD02/night_1km/ /scratch/fslippe/modis/MOD02/may-nov_2021/ /scratch/fslippe/modis/MOD02/cao_test_data/\"\n",
    "\n",
    "\n",
    "bands=[29]\n",
    "#max_vals = np.load(\"%smodels/max_vals_dnb_l95_z50_ps128_(29)_cao_months_202012-202111.npy\" %data_loc)\n",
    "from autoencoder import SobelFilterLayer, SimpleAutoencoder\n",
    "print(len(bands))\n",
    "\n",
    "#encoder = load_model(\"/uio/hume/student-u37/fslippe/data/models/winter_2020_21_band(6,20,29)_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/scratch/fslippe/modis/MOD02/training_data/patch_size_128/train_dnb_l95_z50_ps128_band29_2023.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m train_2021 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scratch/fslippe/modis/MOD02/training_data/patch_size_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/train_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m(patch_size, model_run_name, \u001b[38;5;241m2021\u001b[39m))\n\u001b[1;32m      9\u001b[0m train_2022 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scratch/fslippe/modis/MOD02/training_data/patch_size_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/train_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m(patch_size, model_run_name, \u001b[38;5;241m2022\u001b[39m))\n\u001b[0;32m---> 10\u001b[0m train_2023 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/scratch/fslippe/modis/MOD02/training_data/patch_size_\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m/train_\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_run_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2023\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load test data \u001b[39;00m\n\u001b[1;32m     13\u001b[0m test_2018 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scratch/fslippe/modis/MOD02/training_data/patch_size_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/test_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m(patch_size, model_run_name, \u001b[38;5;241m2018\u001b[39m))\n",
      "File \u001b[0;32m/opt/software/easybuild/software/SciPy-bundle/2021.10-foss-2021b/lib/python3.9/site-packages/numpy/lib/npyio.py:417\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 417\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    418\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/scratch/fslippe/modis/MOD02/training_data/patch_size_128/train_dnb_l95_z50_ps128_band29_2023.npy'"
     ]
    }
   ],
   "source": [
    "# Load training data \n",
    "patch_size = 128\n",
    "model_run_name = \"dnb_l95_z50_ps%s_band29\" %(patch_size)\n",
    "\n",
    "train_2018 = np.load(\"/scratch/fslippe/modis/MOD02/training_data/patch_size_%s/train_%s_%s.npy\" %(patch_size, model_run_name, 2018))\n",
    "train_2019 = np.load(\"/scratch/fslippe/modis/MOD02/training_data/patch_size_%s/train_%s_%s.npy\" %(patch_size, model_run_name, 2019))\n",
    "train_2020 = np.load(\"/scratch/fslippe/modis/MOD02/training_data/patch_size_%s/train_%s_%s.npy\" %(patch_size, model_run_name, 2020))\n",
    "train_2021 = np.load(\"/scratch/fslippe/modis/MOD02/training_data/patch_size_%s/train_%s_%s.npy\" %(patch_size, model_run_name, 2021))\n",
    "train_2022 = np.load(\"/scratch/fslippe/modis/MOD02/training_data/patch_size_%s/train_%s_%s.npy\" %(patch_size, model_run_name, 2022))\n",
    "train_2023 = np.load(\"/scratch/fslippe/modis/MOD02/training_data/patch_size_%s/train_%s_%s.npy\" %(patch_size, model_run_name, 2023))\n",
    "\n",
    "# Load test data \n",
    "test_2018 = np.load(\"/scratch/fslippe/modis/MOD02/training_data/patch_size_%s/test_%s_%s.npy\" %(patch_size, model_run_name, 2018))\n",
    "test_2019 = np.load(\"/scratch/fslippe/modis/MOD02/training_data/patch_size_%s/test_%s_%s.npy\" %(patch_size, model_run_name, 2019))\n",
    "test_2020 = np.load(\"/scratch/fslippe/modis/MOD02/training_data/patch_size_%s/test_%s_%s.npy\" %(patch_size, model_run_name, 2020))\n",
    "test_2021 = np.load(\"/scratch/fslippe/modis/MOD02/training_data/patch_size_%s/test_%s_%s.npy\" %(patch_size, model_run_name, 2021))\n",
    "test_2022 = np.load(\"/scratch/fslippe/modis/MOD02/training_data/patch_size_%s/test_%s_%s.npy\" %(patch_size, model_run_name, 2022))\n",
    "test_2023 = np.load(\"/scratch/fslippe/modis/MOD02/training_data/patch_size_%s/test_%s_%s.npy\" %(patch_size, model_run_name, 2023))\n",
    "\n",
    "# Combine all\n",
    "combined_train_data = np.concatenate((train_2018, train_2019, train_2020, train_2021, train_2022, train_2023), axis=0)\n",
    "combined_test_data = np.concatenate((test_2018, test_2019, test_2020, test_2021, test_2022, test_2023), axis=0)\n",
    "max_val = np.max(combined_train_data)\n",
    "min_val = np.min(combined_train_data) \n",
    "print(\"number of patches:\", len(combined_train_data))\n",
    "print(\"mean:\", np.mean(combined_train_data))\n",
    "print(\"max:\", max_val)\n",
    "print(\"min:\", min_val)\n",
    "normlized_train_data = (combined_train_data - min_val) / (max_val - min_val)\n",
    "normlized_test_data = (combined_test_data - min_val) / (max_val - min_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "patches_per_file = 50000 / 128 * patch_size\n",
    "\n",
    "for i in range(0, len(combined_train_data), patches_per_file):\n",
    "    print(i)\n",
    "    chunk = patches[i: i+patches_per_file]\n",
    "    write_tfrecord(f'/scratch/fslippe/modis/MOD02/training_data/tf_data/normalized_trainingpatches_{model_run_name}_{i//patches_per_file}.tfrecord', chunk)\n",
    "\n",
    "np.save(\"/uio/hume/student-u37/fslippe/data/models/max_vals_%s.npy\" %(model_run_name), max_val)\n",
    "np.save(\"/scratch/fslippe/modis/MOD02/training_data/tf_data/normalized_valpatches_%s\" %(model_run_name), val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mencoder\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
