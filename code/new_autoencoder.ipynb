{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Reshape\n",
    "from sklearn.feature_extraction import image as sk_image\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from keras.models import Model\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.signal import convolve2d\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from pyhdf.SD import SD, SDC\n",
    "import matplotlib as mpl\n",
    "#tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "\n",
    "from sklearn.feature_extraction.image import extract_patches_2d, reconstruct_from_patches_2d\n",
    "from pyhdf.error import HDF4Error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 15:20:27.414516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21336 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:25:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "bands = [1,2]\n",
    "\n",
    "#bands = [6, 7, 20, 28, 28, 31]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file\n"
     ]
    }
   ],
   "source": [
    "#folder = \"/uio/hume/student-u37/fslippe/data/training_data/MOD02QKM/normalized_data/\"\n",
    "folder = \"/uio/hume/student-u37/fslippe/data/nird_mount/MOD02QKM_202012-202104/normalized_data/\"\n",
    "\n",
    "#folder = \"/uio/hume/student-u37/fslippe/data/nird_mount/MOD02QKM_202012-202104/normalized_data/\"\n",
    "\n",
    "all_files = [f for f in os.listdir(folder) if f.endswith('.npz')]\n",
    "\n",
    "def process_file(file):\n",
    "    print(\"file\")\n",
    "    loaded = np.load(folder + file)\n",
    "    arrays_from_file = [loaded[key][:,:,0] for key in loaded]# if loaded[key].shape[0] >= 256]\n",
    "    return arrays_from_file\n",
    "\n",
    "# Use a process pool to process each file in parallel\n",
    "with ProcessPoolExecutor(max_workers = len(all_files)) as executor:\n",
    "    X_lists = list(executor.map(process_file, all_files))\n",
    "\n",
    "# Flatten the result\n",
    "X = [item for sublist in X_lists for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input should already be normalized. Call self.normalize to normalize list of data\n",
      "(651, 256, 256, 2)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 15:02:36.467207: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 6s 57ms/step - loss: 0.2157\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.0956\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0067\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.0034\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.0021\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0018\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0017\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0017\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0016\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.0016\n",
      "(483, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0485\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0485\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0485\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0485\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.0485\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 0.0485\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.0485\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0485\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0485\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.0485\n",
      "(651, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.0119\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.0119\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0119\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0119\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0119\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.0119\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.0119\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0119\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0119\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.0119\n",
      "(105, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.0374\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0374\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0374\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0374\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0374\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0374\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0374\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0374\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0374\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0374\n",
      "(63, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 514ms/step - loss: 0.0043\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0043\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0043\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0043\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0043\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0043\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0043\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0043\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0043\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0043\n",
      "(567, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 66ms/step - loss: 0.0037\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0037\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0037\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0037\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0037\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0037\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.0037\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.0037\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.0037\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.0037\n",
      "(189, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 110ms/step - loss: 0.0357\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0357\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0357\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0357\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0357\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0357\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0357\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0357\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0357\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0357\n",
      "(441, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 1s 70ms/step - loss: 7.7655e-04\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 7.7609e-04\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 7.7562e-04\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 7.7524e-04\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 7.7494e-04\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 7.7471e-04\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 7.7453e-04\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 7.7438e-04\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 7.7426e-04\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 7.7416e-04\n",
      "(651, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 1s 55ms/step - loss: 0.0031\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0031\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0031\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.0031\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0031\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0031\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0031\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.0031\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.0031\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 1s 60ms/step - loss: 0.0031\n",
      "(273, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.0249\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0249\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0249\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0249\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0249\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0249\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0249\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0249\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0249\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.0249\n",
      "(147, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 5.1963e-04\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.1961e-04\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.1957e-04\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.1953e-04\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.1949e-04\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.1944e-04\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 5.1940e-04\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.1936e-04\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.1933e-04\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.1930e-04\n",
      "(567, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 4s 204ms/step - loss: 0.0315\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0315\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0315\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0315\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0315\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0315\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0315\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0315\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0315\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0315\n",
      "(609, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 2s 95ms/step - loss: 0.0011\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.0011\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.0011\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.0011\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.0011\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.0011\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.0011\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.0011\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 1s 63ms/step - loss: 0.0011\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 2s 97ms/step - loss: 0.0011\n",
      "(357, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0149\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0149\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0149\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.0149\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0149\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.0149\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0149\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0149\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0149\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.0149\n",
      "(525, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "17/17 [==============================] - 2s 66ms/step - loss: 8.7316e-04\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 8.7315e-04\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 8.7315e-04\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 8.7314e-04\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 8.7314e-04\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 1s 46ms/step - loss: 8.7313e-04\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 8.7313e-04\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 8.7313e-04\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 8.7312e-04\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 8.7312e-04\n",
      "(105, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0404\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0404\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0404\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0404\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0404\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0404\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0404\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0404\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0404\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0404\n",
      "(441, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 3s 204ms/step - loss: 0.0476\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0476\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0476\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0476\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.0476\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.0476\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.0476\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 0.0476\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 0.0476\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.0476\n",
      "(315, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 6.3285e-04\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 6.3284e-04\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 6.3284e-04\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 6.3284e-04\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 6.3283e-04\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 6.3283e-04\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 6.3283e-04\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 6.3282e-04\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 6.3282e-04\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 6.3282e-04\n",
      "(63, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0283\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0283\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0283\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0283\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0283\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0283\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0283\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0283\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0283\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0283\n",
      "(651, 256, 256, 2)\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 4s 146ms/step - loss: 0.0213\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.0213\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.0213\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.0213\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.0213\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.0213\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.0213\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.0213\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.0213\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 1s 66ms/step - loss: 0.0213\n"
     ]
    }
   ],
   "source": [
    "import autoencoder\n",
    "import importlib\n",
    "importlib.reload(autoencoder)\n",
    "from autoencoder import SobelFilterLayer, SimpleAutoencoder\n",
    "bands = [1, 2]\n",
    "patch_size = 256\n",
    "\n",
    "autoencoder = SimpleAutoencoder(len(bands), patch_size, patch_size)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "model = autoencoder.model(X, optimizer=optimizer, threshold=0.09,loss=\"combined\")\n",
    "folder = \"/uio/hume/student-u37/fslippe/data/nird_mount/MOD02QKM_202012-202104/normalized_data/\"\n",
    "\n",
    "all_files = [f for f in os.listdir(folder) if f.endswith('.npz')][:5]\n",
    "\n",
    "for file in all_files:\n",
    "    data = process_file(file)\n",
    "    for i in range(len(data)):\n",
    "        patches = autoencoder.extract_patches(data[i])\n",
    "        print(patches.shape)\n",
    "        model.fit(patches, patches, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input should already be normalized. Call self.normalize to normalize list of data\n",
      "Extracting patches...\n",
      "Extracting image 0 of 30\n",
      "Extracting image 1 of 30\n",
      "Extracting image 2 of 30\n",
      "Extracting image 3 of 30\n",
      "Extracting image 4 of 30\n",
      "Extracting image 5 of 30\n",
      "Extracting image 6 of 30\n",
      "Extracting image 7 of 30\n",
      "Extracting image 8 of 30\n",
      "Extracting image 9 of 30\n",
      "Extracting image 10 of 30\n",
      "Extracting image 11 of 30\n",
      "Extracting image 12 of 30\n",
      "Extracting image 13 of 30\n",
      "Extracting image 14 of 30\n",
      "Extracting image 15 of 30\n",
      "Extracting image 16 of 30\n",
      "Extracting image 17 of 30\n",
      "Extracting image 18 of 30\n",
      "Extracting image 19 of 30\n",
      "Extracting image 20 of 30\n",
      "Extracting image 21 of 30\n",
      "Extracting image 22 of 30\n",
      "Extracting image 23 of 30\n",
      "Extracting image 24 of 30\n",
      "Extracting image 25 of 30\n",
      "Extracting image 26 of 30\n",
      "Extracting image 27 of 30\n",
      "Extracting image 28 of 30\n",
      "Extracting image 29 of 30\n",
      "Patches shape:  (3301, 256, 256, 1)\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 15:17:08.930181: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 9s 37ms/step - loss: 0.0417\n",
      "Epoch 2/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0101\n",
      "Epoch 3/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0079\n",
      "Epoch 4/200\n",
      "104/104 [==============================] - 4s 37ms/step - loss: 0.0075\n",
      "Epoch 5/200\n",
      "104/104 [==============================] - 4s 37ms/step - loss: 0.0073\n",
      "Epoch 6/200\n",
      "104/104 [==============================] - 4s 39ms/step - loss: 0.0072\n",
      "Epoch 7/200\n",
      "104/104 [==============================] - 4s 35ms/step - loss: 0.0071\n",
      "Epoch 8/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0070\n",
      "Epoch 9/200\n",
      "104/104 [==============================] - 4s 38ms/step - loss: 0.0070\n",
      "Epoch 10/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0069\n",
      "Epoch 11/200\n",
      "104/104 [==============================] - 4s 37ms/step - loss: 0.0069\n",
      "Epoch 12/200\n",
      "104/104 [==============================] - 4s 38ms/step - loss: 0.0068\n",
      "Epoch 13/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0068\n",
      "Epoch 14/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0067\n",
      "Epoch 15/200\n",
      "104/104 [==============================] - 4s 37ms/step - loss: 0.0067\n",
      "Epoch 16/200\n",
      "104/104 [==============================] - 4s 35ms/step - loss: 0.0067\n",
      "Epoch 17/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0066\n",
      "Epoch 18/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0066\n",
      "Epoch 19/200\n",
      "104/104 [==============================] - 4s 35ms/step - loss: 0.0066\n",
      "Epoch 20/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0066\n",
      "Epoch 21/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0065\n",
      "Epoch 22/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0065\n",
      "Epoch 23/200\n",
      "104/104 [==============================] - 4s 35ms/step - loss: 0.0065\n",
      "Epoch 24/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0064\n",
      "Epoch 25/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0064\n",
      "Epoch 26/200\n",
      "104/104 [==============================] - 4s 35ms/step - loss: 0.0064\n",
      "Epoch 27/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0064\n",
      "Epoch 28/200\n",
      "104/104 [==============================] - 4s 37ms/step - loss: 0.0064\n",
      "Epoch 29/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0064\n",
      "Epoch 30/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0063\n",
      "Epoch 31/200\n",
      "104/104 [==============================] - 4s 37ms/step - loss: 0.0063\n",
      "Epoch 32/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0063\n",
      "Epoch 33/200\n",
      "104/104 [==============================] - 4s 35ms/step - loss: 0.0063\n",
      "Epoch 34/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0063\n",
      "Epoch 35/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0062\n",
      "Epoch 36/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0063\n",
      "Epoch 37/200\n",
      "104/104 [==============================] - 4s 35ms/step - loss: 0.0062\n",
      "Epoch 38/200\n",
      "104/104 [==============================] - 4s 35ms/step - loss: 0.0062\n",
      "Epoch 39/200\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0062\n",
      "Epoch 40/200\n",
      " 71/104 [===================>..........] - ETA: 1s - loss: 0.0061"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m autoencoder \u001b[39m=\u001b[39m SimpleAutoencoder(\u001b[39m1\u001b[39m, patch_size, patch_size)\n\u001b[1;32m     10\u001b[0m optimizer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m autoencoder\u001b[39m.\u001b[39;49mfit(X, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, optimizer\u001b[39m=\u001b[39;49moptimizer, threshold\u001b[39m=\u001b[39;49m\u001b[39m0.09\u001b[39;49m,loss\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcombined\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     14\u001b[0m \u001b[39m# print(X[0].shape)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# #autoencoder = simple_autoencoder([data_01], patch_size)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m# autoencoder = simple_autoencoder(1, (2040, 1354), patch_size)    \u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m# autoencoder.fit(X, epochs=5, batch_size=256)\u001b[39;00m\n",
      "File \u001b[0;32m~/master_project/code/autoencoder.py:166\u001b[0m, in \u001b[0;36mSimpleAutoencoder.fit\u001b[0;34m(self, normalized_datasets, epochs, batch_size, loss, threshold, optimizer, predict_self)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautoencoder \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mModel(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder_input, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoded))\n\u001b[1;32m    165\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautoencoder\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer, loss\u001b[39m=\u001b[39mloss_func)  \u001b[39m# Using combined loss\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mautoencoder\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpatches, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpatches, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size)\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m predict_self:\n\u001b[1;32m    169\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict()\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/keras/engine/training.py:1221\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1221\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1222\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1223\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/keras/callbacks.py:436\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \n\u001b[1;32m    431\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 436\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/keras/callbacks.py:295\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    294\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 295\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    298\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/keras/callbacks.py:316\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    314\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 316\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    319\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/keras/callbacks.py:354\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    353\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 354\u001b[0m   hook(batch, logs)\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    357\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/keras/callbacks.py:1032\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1032\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/keras/callbacks.py:1104\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1102\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1103\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1104\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1105\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/keras/utils/tf_utils.py:554\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(x) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    552\u001b[0m   \u001b[39mreturn\u001b[39;00m t  \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m--> 554\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/tensorflow/python/util/nest.py:869\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    866\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    868\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    870\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/tensorflow/python/util/nest.py:869\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    866\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    868\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    870\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/keras/utils/tf_utils.py:550\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    549\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 550\u001b[0m     x \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    551\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(x) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    552\u001b[0m   \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1149\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \n\u001b[1;32m   1128\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1149\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1115\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1114\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1115\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1116\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#from autoencoder import SobelFilterLayer, SimpleAutoencoder\n",
    "import autoencoder\n",
    "import importlib\n",
    "importlib.reload(autoencoder)\n",
    "from autoencoder import SobelFilterLayer, SimpleAutoencoder\n",
    "\n",
    "bands = [1, 2]\n",
    "patch_size = 256\n",
    "autoencoder = SimpleAutoencoder(1, patch_size, patch_size)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "\n",
    "autoencoder.fit(X, epochs=200, batch_size=32, optimizer=optimizer, threshold=0.09,loss=\"combined\")\n",
    "# print(X[0].shape)\n",
    "# #autoencoder = simple_autoencoder([data_01], patch_size)\n",
    "# autoencoder = simple_autoencoder(1, (2040, 1354), patch_size)    \n",
    "# autoencoder.fit(X, epochs=5, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.autoencoder.save(\"/uio/hume/student-u37/fslippe/data/models/test_5day_autoencoder\")\n",
    "autoencoder.encoder.save(\"/uio/hume/student-u37/fslippe/data/models/test_5day_encoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import SobelFilterLayer, SimpleAutoencoder\n",
    "patch_size = 256\n",
    "from tensorflow.keras.models import load_model\n",
    "autoencoder_predict = SimpleAutoencoder(len(bands), patch_size, patch_size)\n",
    "\n",
    "encoder = load_model(\"/uio/hume/student-u37/fslippe/data/models/test_5day_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder.autoencoder = model\n",
    "\n",
    "X_test = X\n",
    "\n",
    "cluster_map = autoencoder_predict.kmeans(X_test, n_clusters=10, encoder=encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(X_test[2],axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# Determine global min and max labels\n",
    "global_min = np.min([np.min(cm) for cm in cluster_map])\n",
    "global_max = np.max([np.max(cm) for cm in cluster_map])\n",
    "\n",
    "norm = Normalize(vmin=global_min, vmax=global_max)\n",
    "\n",
    "for i in range(len(cluster_map)):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=[10, 8])\n",
    "    \n",
    "    cb = axs[0].imshow(cluster_map[i], cmap=\"tab10\", norm=norm)\n",
    "    plt.colorbar(cb, ax=axs[0])\n",
    "    \n",
    "    cb = axs[1].imshow(X_test[i][:, :, 0])\n",
    "    plt.colorbar(cb, ax=axs[1])\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/uio/hume/student-u37/fslippe/data/cao/\"\n",
    "i=0\n",
    "print(folder + all_files[i])\n",
    "hdf = SD(folder + all_files[i], SDC.READ)\n",
    "print(hdf.attributes())\n",
    "lon = hdf.select('Longitude')[:]\n",
    "lat = hdf.select('Latitude')[:]\n",
    "downsample_factor_x = int(lon.shape[0] / cluster_map[i].shape[0])\n",
    "downsample_factor_y = int(lon.shape[1] / cluster_map[i].shape[1])\n",
    "cluster_shape = cluster_map[i].shape\n",
    "lon_d = lon[::downsample_factor_x, ::downsample_factor_y][:cluster_shape[0], :cluster_shape[1]]\n",
    "lat_d = lat[::downsample_factor_x, ::downsample_factor_y][:cluster_shape[0], :cluster_shape[1]]\n",
    "data = hdf.select(\"EV_250_Aggr1km_RefSB\")[:][0]\n",
    "print(data.shape)\n",
    "hdf.select(\"EV_250_Aggr1km_RefSB\").attributes()\n",
    "print(lon.shape)\n",
    "cluster_map[i].shape\n",
    "datasets = hdf.datasets()   \n",
    "for idx, sds in enumerate(datasets.keys()):\n",
    "    print(idx, sds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axs= plt.subplots(1,2)\n",
    "axs[0].imshow(cluster_map[i])\n",
    "axs[1].imshow(X[i][:,:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = ccrs.NorthPolarStereo()\n",
    "fig, axs = plt.subplots(1, 2, figsize=[10,5], subplot_kw={'projection': projection}, dpi=300)\n",
    "cb = axs[0].pcolormesh(lon_d, lat_d, cluster_map[i], transform=ccrs.PlateCarree(), cmap=\"jet\")  \n",
    "axs[0].coastlines()\n",
    "gl = axs[0].gridlines(draw_labels=True)\n",
    "plt.colorbar(cb)\n",
    "\n",
    "cb = axs[1].pcolormesh(lon, lat, data, transform=ccrs.PlateCarree(), vmin=0)  \n",
    "axs[1].coastlines()\n",
    "gl = axs[1].gridlines(draw_labels=True)\n",
    "plt.colorbar(cb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patches_predict = autoencoder.extract_patches(dataset_5.reshape((1,dataset_5.shape[0], dataset_5.shape[1], 1)))\n",
    "# predict = autoencoder.autoencoder.predict(patches_predict)\n",
    "# predict.shape\n",
    "\n",
    "# #for i in range(83, 90, 2):\n",
    "# pictures = 12\n",
    "# patch_start = 68\n",
    "# fig, axs = plt.subplots(2, pictures, figsize=[pictures*2,5])\n",
    "# i=0\n",
    "# for patch_number in range(patch_start, patch_start+pictures):\n",
    "#     axs[0, i].imshow(patches_predict[patch_number], cmap=\"gray\")\n",
    "#     axs[1, i].imshow(predict[patch_number,:,:,0], cmap=\"gray\")\n",
    "    \n",
    "#     # Turn off ticks and axis labels for both x and y\n",
    "#     axs[0, i].set_yticks([])\n",
    "#     axs[0, i].set_xticks([])\n",
    "#     axs[0, i].axis('off')\n",
    "    \n",
    "#     axs[1, i].set_yticks([])\n",
    "#     axs[1, i].set_xticks([])\n",
    "#     axs[1, i].axis('off')\n",
    "    \n",
    "#     i += 1\n",
    "# plt.tight_layout()\n",
    "\n",
    "patches_predict = autoencoder2.extract_patches(dataset_5.reshape((1,dataset_5.shape[0], dataset_5.shape[1], 1)))\n",
    "predict = autoencoder2.autoencoder.predict(patches_predict)\n",
    "print(predict.shape)\n",
    "\n",
    "#for i in range(83, 90, 2):\n",
    "pictures = 10\n",
    "patch_start = 320\n",
    "fig, axs = plt.subplots(2, pictures, figsize=[pictures*2,5])\n",
    "i=0\n",
    "for patch_number in range(patch_start, patch_start+pictures):\n",
    "    axs[0, i].imshow(patches_predict[patch_number], cmap=\"gray\")\n",
    "    axs[1, i].imshow(predict[patch_number,:,:,0], cmap=\"gray\")\n",
    "    \n",
    "    # Turn off ticks and axis labels for both x and y\n",
    "    axs[0, i].set_yticks([])\n",
    "    axs[0, i].set_xticks([])\n",
    "    axs[0, i].axis('off')\n",
    "    \n",
    "    axs[1, i].set_yticks([])\n",
    "    axs[1, i].set_xticks([])\n",
    "    axs[1, i].axis('off')\n",
    "    \n",
    "    i += 1\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(dataset_5, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "cmp = axes[0].imshow(dataset_2, cmap='gray')\n",
    "plt.colorbar(cmp, ax=axes[0])\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "cmp = axes[1].imshow(labels_img, cmap='tab10')\n",
    "plt.colorbar(cmp, ax=axes[1])\n",
    "axes[1].set_title('Clustered Image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(flattened_input, encoded)\n",
    "encoded_imgs = encoder.predict(data)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reduce the encoded images to 2D using PCA\n",
    "pca = PCA(n_components=2)\n",
    "encoded_imgs_2d = pca.fit_transform(encoded_imgs)\n",
    "\n",
    "# Now cluster the 2D encoded images\n",
    "n_clusters = 5  # Define the number of clusters you want\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "cluster_assignments = kmeans.fit_predict(encoded_imgs_2d)\n",
    "\n",
    "print(cluster_assignments.shape)\n",
    "\n",
    "# If you want to visualize the clusters using matplotlib:\n",
    "plt.scatter(encoded_imgs_2d[:, 0], encoded_imgs_2d[:, 1], c=cluster_assignments, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.title('Clusters in 2D')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(dataset_2)\n",
    "fig, axs = plt.subplots(1, 2, figsize=[10,5])\n",
    "\n",
    "cmp = axs[0].imshow(dataset_2, cmap=\"gray\")\n",
    "plt.colorbar(cmp)\n",
    "cmp = axs[1].imshow(decoded_imgs,cmap=\"gray\")\n",
    "plt.colorbar(cmp)\n",
    "\n",
    "#decoded_imgs_2d = decoded_imgs.reshape((-1, *input_shape))\n",
    "# plt.contourf(decoded_imgs_2d)\n",
    "# plt.show(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs_reshaped = decoded_imgs.reshape(-1, 1)\n",
    "\n",
    "n_clusters = 3\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(decoded_imgs_reshaped)\n",
    "labels = kmeans.labels_\n",
    "labels_reshaped = labels.reshape(2040, 1354)\n",
    "\n",
    "# Assuming `original_img` is your original image\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "cmp = axes[0].imshow(dataset_2, cmap='gray')  # or just cmap depending on the nature of your image\n",
    "plt.colorbar(cmp)\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "cmp = axes[1].imshow(labels_reshaped, cmap='tab10')  # 'tab10' is a colormap with distinct colors\n",
    "plt.colorbar(cmp)\n",
    "axes[1].set_title('Clustered Image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "block_size = (10, 10)  # Change accordingly\n",
    "n_clusters = 5\n",
    "\n",
    "# Divide the image into blocks and calculate the mean for each block\n",
    "blocks = []\n",
    "for i in range(0, decoded_imgs.shape[0], block_size[0]):\n",
    "    for j in range(0, decoded_imgs.shape[1], block_size[1]):\n",
    "        block = decoded_imgs[i:i+block_size[0], j:j+block_size[1]]\n",
    "        block_mean = np.mean(block)\n",
    "        blocks.append(block_mean)\n",
    "\n",
    "blocks = np.array(blocks).reshape(-1, 1)\n",
    "\n",
    "# Cluster the blocks\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(blocks)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Construct the clustered image\n",
    "clustered_img = np.zeros_like(decoded_imgs)\n",
    "label_idx = 0\n",
    "for i in range(0, decoded_imgs.shape[0], block_size[0]):\n",
    "    for j in range(0, decoded_imgs.shape[1], block_size[1]):\n",
    "        clustered_img[i:i+block_size[0], j:j+block_size[1]] = labels[label_idx]\n",
    "        label_idx += 1\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Assuming `original_img` is your original image\n",
    "axes[0].imshow(dataset_2, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(clustered_img, cmap='tab10')  # 'tab10' for distinct colors\n",
    "axes[1].set_title('Clustered Image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EasyBuild Python 3.9.6",
   "language": "python",
   "name": "easybuild-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
