{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.layers import Input, Dense, Flatten, Reshape\n",
    "from sklearn.feature_extraction import image as sk_image\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from keras.models import Model\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.signal import convolve2d\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from pyhdf.SD import SD, SDC\n",
    "import matplotlib as mpl\n",
    "#tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "from extract_training_data import *\n",
    "from sklearn.feature_extraction.image import extract_patches_2d, reconstruct_from_patches_2d\n",
    "from pyhdf.error import HDF4Error\n",
    "from functions import *\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 14:00:14.658430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21336 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:25:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_policy(policy)\n",
    "\n",
    "#bands = [6, 7, 20, 28, 28, 31]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bands = [6,20,29]\n",
    "bands = [1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/fslippe/modis/MOD02/daytime_1km/MOD021KM.A2020336.0800.061.2020337214455.hdf\n",
      "0 Latitude\n",
      "1 Longitude\n",
      "2 EV_1KM_RefSB\n",
      "3 EV_1KM_RefSB_Uncert_Indexes\n",
      "4 EV_1KM_Emissive\n",
      "5 EV_1KM_Emissive_Uncert_Indexes\n",
      "6 EV_250_Aggr1km_RefSB\n",
      "7 EV_250_Aggr1km_RefSB_Uncert_Indexes\n",
      "8 EV_250_Aggr1km_RefSB_Samples_Used\n",
      "9 EV_500_Aggr1km_RefSB\n",
      "10 EV_500_Aggr1km_RefSB_Uncert_Indexes\n",
      "11 EV_500_Aggr1km_RefSB_Samples_Used\n",
      "12 Height\n",
      "13 SensorZenith\n",
      "14 SensorAzimuth\n",
      "15 Range\n",
      "16 SolarZenith\n",
      "17 SolarAzimuth\n",
      "18 gflags\n",
      "19 EV_Band26\n",
      "20 EV_Band26_Uncert_Indexes\n",
      "21 Band_250M\n",
      "22 Band_500M\n",
      "23 Band_1KM_RefSB\n",
      "24 Band_1KM_Emissive\n",
      "25 Noise in Thermal Detectors\n",
      "26 Change in relative responses of thermal detectors\n",
      "27 DC Restore Change for Thermal Bands\n",
      "28 DC Restore Change for Reflective 250m Bands\n",
      "29 DC Restore Change for Reflective 500m Bands\n",
      "30 DC Restore Change for Reflective 1km Bands\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/110 [00:00<?, ?it/s]/opt/software/easybuild/software/SciPy-bundle/2021.10-foss-2021b/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/software/easybuild/software/SciPy-bundle/2021.10-foss-2021b/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 110/110 [00:24<00:00,  4.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "518"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PROCESSING .hdf files\n",
    "import extract_training_data\n",
    "import importlib\n",
    "importlib.reload(extract_training_data)\n",
    "from extract_training_data import *\n",
    "#folder = \"/uio/hume/student-u37/fslippe/data/training_data/MOD02QKM/normalized_data/\"\n",
    "folder = \"/scratch/fslippe/modis/MOD02/daytime_1km/\"\n",
    "\n",
    "#folder = \"/uio/hume/student-u37/fslippe/data/nird_mount/MOD02QKM_202012-202104/normalized_data/\"\n",
    "\n",
    "start = \"20201201\"\n",
    "end = \"20210416\"\n",
    "#end = \"20201230\"\n",
    "\n",
    "#dates = [\"20210303\"]#, \"20210322\"]#, \"20210323\"]\n",
    "#dates_converted = []\n",
    "#for date in dates:\n",
    "#    dates_converted.append(convert_to_day_of_year(date))\n",
    "#bands = [6,20,29]\n",
    "\n",
    "start_converted = convert_to_day_of_year(start)\n",
    "end_converted = convert_to_day_of_year(end)\n",
    "#print(start_converted)\n",
    "#print(end_converted)\n",
    "#x = [xi for xi in  extract_250m_data(folder, bands=[1], date_list=dates_converted) if xi.shape[0] > 256]\n",
    "x = [xi for xi in  extract_1km_data(folder, bands=bands, start_date=start_converted, end_date=end_converted) if xi.shape[0] > 64]\n",
    "\n",
    "len(x)\n",
    "#x = extract_250m_data(folder, bands=[1], start_date=start_converted, end_date=end_converted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x2 = [xi for xi in  extract_1km_data(folder, bands=[6], start_date=start_converted, end_date=end_converted) if xi.shape[0] > 64]\n",
    "# x3 = [xi for xi in  extract_1km_data(folder, bands=[1], start_date=start_converted, end_date=end_converted) if xi.shape[0] > 64]\n",
    "# x4 = [xi for xi in  extract_1km_data(folder, bands=[7], start_date=start_converted, end_date=end_converted) if xi.shape[0] > 64]\n",
    "# x5 = [xi for xi in  extract_1km_data(folder, bands=[20], start_date=start_converted, end_date=end_converted) if xi.shape[0] > 64]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1,5, dpi=300)\n",
    "# i = 15\n",
    "# cb = axs[4].imshow(x[i][:,:,0], cmap=\"gray\")\n",
    "# plt.colorbar(cb)\n",
    "# axs[1].imshow(x2[i], cmap=\"gray\")\n",
    "# axs[0].imshow(x3[i], cmap=\"gray\")\n",
    "# axs[2].imshow(x4[i], cmap=\"gray\")\n",
    "# axs[3].imshow(x5[i], cmap=\"gray\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input should already be normalized. Call self.normalize to normalize list of data\n"
     ]
    }
   ],
   "source": [
    "import autoencoder\n",
    "import importlib\n",
    "importlib.reload(autoencoder)\n",
    "from autoencoder import SobelFilterLayer, SimpleAutoencoder\n",
    "patch_size = 64\n",
    "\n",
    "autoencoder = SimpleAutoencoder(len(bands), patch_size, patch_size)\n",
    "#x = autoencoder.normalize(x)\n",
    "#optimizer = mixed_precision.LossScaleOptimizer(tf.keras.optimizers.Adam(learning_rate=1e-4), loss_scale='dynamic')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "model = autoencoder.model(optimizer=optimizer, loss=\"combined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = np.concatenate([autoencoder.extract_patches(n_d) for n_d in x], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished split\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data\n",
    "patches, val_data = train_test_split(patches, test_size=0.1, random_state=42)\n",
    "print(\"finished split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300169, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "print(patches.shape)\n",
    "print(val_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[517.38549888]]]]\n"
     ]
    }
   ],
   "source": [
    "min_val = 0\n",
    "max_val = np.max(patches, axis=(0,1,2), keepdims=True)\n",
    "print(max_val)\n",
    "patches = (patches - min_val) / (max_val - min_val)\n",
    "val_data = (val_data - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/scratch/fslippe/modis/MOD02/test_data/normalized_testpatches_band(1)_winter20_21.npy\", val_data)\n",
    "np.save(\"/scratch/fslippe/modis/MOD02/training_data/normalized_trainingpatches_band(1)_winter20_21.npy\", patches)\n",
    "# val_data = np.load(\"/uio/hume/student-u37/fslippe/data/models/winter_2020_21_val_patches.npy\")\n",
    "# patches = np.load(\"/uio/hume/student-u37/fslippe/data/models/winter_2020_21_train_patches.npy\")[:int(170e3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE TRAIN TEST PATCHES \n",
    "# patches = np.load(\"/scratch/fslippe/modis/MOD02/training_data/normalized_trainingpatches_bands6,20,29_winter20_21.npy\")[::4]\n",
    "# val_data  = np.load(\"/scratch/fslippe/modis/MOD02/test_data/normalized_testpatches_bands6,20,29_winter20_21.npy\")[::4]\n",
    "# patches.shape\n",
    "\n",
    "# print(np.mean(patches, axis=(0,1,2)))\n",
    "print(patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 14:08:18.042893: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4917968896 exceeds 10% of free system memory.\n",
      "2023-09-26 14:08:31.579837: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4917968896 exceeds 10% of free system memory.\n",
      "2023-09-26 14:08:34.867789: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4917968896 exceeds 10% of free system memory.\n",
      "2023-09-26 14:08:38.119990: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4917968896 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 14:08:43.385161: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/9381 [=====>........................] - ETA: 55s - loss: 0.0104"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/uio/hume/student-u37/fslippe/master_project/code/new_autoencoder.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmimi/uio/hume/student-u37/fslippe/master_project/code/new_autoencoder.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m### STANDARD FIT\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmimi/uio/hume/student-u37/fslippe/master_project/code/new_autoencoder.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmimi/uio/hume/student-u37/fslippe/master_project/code/new_autoencoder.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(patches, patches, validation_data\u001b[39m=\u001b[39;49m(val_data,val_data), epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/keras/engine/training.py:1208\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1206\u001b[0m callbacks\u001b[39m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m   1207\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m-> 1208\u001b[0m   \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   1209\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1210\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1211\u001b[0m         epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1212\u001b[0m         step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1213\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1214\u001b[0m         _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1215\u001b[0m       callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m/opt/software/easybuild/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/keras/engine/data_adapter.py:1250\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m   \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1250\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m   1251\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[1;32m   1252\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1254\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m\n\u001b[1;32m   1255\u001b[0m     original_spe)\n\u001b[1;32m   1257\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### STANDARD FIT\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model.fit(patches, patches, validation_data=(val_data,val_data), epochs=100, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_generator():\n",
    "    \"\"\"Generator to yield data from files.\"\"\"\n",
    "    file_list = ['file1.npy', 'file2.npy', ...]\n",
    "    random.shuffle(file_list)  # Shuffle files at the beginning of each epoch\n",
    "    for file_name in file_list:\n",
    "        data = np.load(file_name)\n",
    "        for item in data:\n",
    "            yield item\n",
    "\n",
    "# Define your dataset\n",
    "dataset = tf.data.Dataset.from_generator(data_generator,\n",
    "                                         output_signature=(tf.TensorSpec(shape=(...), dtype=tf.float32)))  # Fill in the shape and type\n",
    "dataset = dataset.shuffle(buffer_size=10000)  # Shuffle data\n",
    "dataset = dataset.batch(32)  # Batch data\n",
    "dataset = dataset.repeat()  # Repeat dataset indefinitely\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)  # Prefetch data\n",
    "steps_per_epoch = ...  \n",
    "\n",
    "model.fit(dataset, epochs=200, steps_per_epoch=steps_per_epoch, validation_data=(val_data, val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"/uio/hume/student-u37/fslippe/data/models/winter_2020_21_autoencoder\")\n",
    "autoencoder.encoder.save(\"/uio/hume/student-u37/fslippe/data/models/winter_2020_21_band(6,20,29)_encoder\")\n",
    "autoencoder.decoder.save(\"/uio/hume/student-u37/fslippe/data/models/winter_2020_21_band(6,20,29)_decoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
